# Домашнее задание по лекции "6.6. Troubleshooting"

## Обязательная задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её нужно прервать.

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

### **Решение:**

> Документация по команде [db.currentOp](https://www.mongodb.com/docs/v5.0/reference/command/currentOp)

> Документация по команде [db.killOp](https://www.mongodb.com/docs/v5.0/reference/method/db.killOp/#mongodb-method-db.killOp)

Для определения длительных запросов нужно воспользоваться запросом `db.currentOp`, где в качестве параметров использовать фильтр по длительности выполнения запроса - в нашем случае **3** минуты.
Запрос будет выглядеть следующим образом: `db.currentOp({"secs_running": {$gte: 180}})`, где `secs_running` - время выполнения запроса в секундах, `gte` - больше или равно, в данном случае **>=180** секунд.

В ответ мы должны получить JSON документ с множеством полей, включая следующие:

  - `op` - тип операции, например `query` - запрос

  - `opid` - уникальный идентификатор операции

  - `query` - текст запроса

  - `active` - выполняется ли данный запрос сейчас - должнен быть `true` если запрос всё ещё в работе

  - `ns` - имя коллекции, к которой относится запрос

  - `secs_running` - время выполнения запроса (собственно по этому полю мы и фильтруем вывод `db.currentOp`)

  - `planSummary` - план по которому MongoDB выполняет запрос

Далее для остановки запроса нужно выполнить команду `db.killOp`, где в качестве параметра указать идентификатор `opid` проблемного запроса, например так: `db.killOp("shardB:79014");`

Для решения проблемы с долгими запросами нужно сначала выяснить какие запросы "подвисают".
Для этого можно воспользоваться либо решением проблем на лету, то есть искать длительные запросы по мере их возникновения как в предыдущем примере командой `db.currentOp`.
Либо воспользоваться профилеровщиком, который сам будет отслеживать длительные запросы и сохранять о них информацию в специальную коллекцию `system.profile`.
Команда установки профилирования может выглядеть следующим образом `db.setProfilingLevel(1, 60000)` - активация (`1`) логирования запросов с длительностью от **1 минуты** (`60000` миллисекунд).
Далее изучаем собранные данные командой `db.system.profile.find().pretty()`

Когда длительные запросы определены нужно выяснить что в них проблемного.
Для этого можно обратить внимание на поле `planSummary` в выводе команды `db.currentOp`, либо на поля `keysExamined`, `docsExamined`, `nreturned`, `execStats` в профилеровщике.
А также воспользоваться функцией `.explain("executionStats")` для проблемного запроса. (Пример вызова: `db.inventory.find( { quantity: { $gte: 100, $lte: 200 } } ).explain("executionStats")`.
Далее нужно либо оптимизировать сами запросы, либо использовать правильные индексы. Если **MongoDB** не может использовать существующие индексы для поиска документов (из ОЗУ) он начинает запрашивать данные из документов с диска, что замедляет выборку.

> Дополнительно использовалась статья [Troubleshooting MongoDB 100% CPU load and slow queries](https://medium.com/mongodb-cowboys/troubleshooting-mongodb-100-cpu-load-and-slow-queries-da622c6e1339)

---

## Обязательная задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL.
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и увеличивается пропорционально количеству реплик сервиса.

При масштабировании сервиса до N реплик вы увидели сначала рост отношения записанных значений к истекшим, а потом блокирку Redis для операций записи

Как вы думаете, в чем может быть проблема?

### **Решение:**

**Redis** - это база данных типа `ключ-значение`, которая чаще всего используется как хранилище временных данных, то есть данных обладающих характеристикой `TimeToLive` (время жизни).

Так как мы используем **Redis** для хранения данных со сроком жизни, то для каждой операции создания ключа через определённый промежуток времени будет исполнена операция чистки.
Рост отношения записанных значений к истекщим, говорит об увеличивающейся нагрузке.
Если конфигурация серсива стабильна, а нагрузка продолжает увеличиваться приводя в итоге к блокировке **Redis** на запись, то это означает, что **Redis** не успевает производить чистку.
В данной ситуации нужно оптимизировать хранение данных **Redis**, например:

- Если допускается, то можно отключить сброс данных на диск, пожертвовав сохранностью в пользу производительности

- Оптимизировать настройки операционной системы (отключить huge_page, настроить swap, заменить HDD на SSD, выполнить подстройку/заменить VM если они используется)

- Оптимизировать/исключить запросы, использующие медленные команды, такие как: `SORT`, `LREM`, `SUNION`. **Redis** работает в однопоточном режиме и пока не выполнится текущий запрос, следующий будет ждать в очереди. Поэтому использование медленных команд может увеличивать очередь.

### *Дополнние от преподавателя (**Олег Букатчук**):*

*Проблема скорей всего в том что вся память занята истекшими в один и тот же момент ключами которые еще не удаленны.*
*Так как Redis использует в основном однопоточную конструкцию, поэтому все запросы обслуживаются последовательно,*
*в связи с этим пока не выполнится очистка, все операции записи блокируются.*

---
 
## Обязательная задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы, пользователи начали жаловаться на ошибки вида:

```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

### **Решение:**

В соответствии с [документацией MySQL](https://dev.mysql.com/doc/refman/8.0/en/error-lost-connection.html) данная ошибка может возникать в следующих случаях:

- Если результатом запроса является большой объём данных (миллионы строк), то может не хватить времени на передачу такого массива данным. По умолчанию на приём отводится 30 секунд. В качестве решения можно повысить время ожидания ответа, изменив переменную [net_read_timeout](https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_net_read_timeout)

- При плохом интернет-соединении или большой дистанции до сервера соединение может быть разорвано по таймауту соединения если оно установлено на несколько некунд и этого времени не хватает на подключение к серверу. В качестве решения можно повысить допустимое время ожидания ответа, изменив переменную [connect_timeout](https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_connect_timeout), либо сократить дистанцию до сервер базы данных (физически переместить сервер баз данных ближе)

- При передачи BLOB полей (набор байт) размер которых превышает установленный предел. В качестве решения можно изменить допустимый размер пакета характеризуемый переменной [max_allowed_packet](https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_max_allowed_packet)

В описании проблемы сказано, что ошибки начали возникать после роста числа записей,
а в тексте ошибки сказано о потере соединения во время выполнения запроса `SELECT`.
Из вышесказанного следует, что СУБД не успевает за отведённое время подготовить и передать запрашиваемые данные.
Для решения нужно точно установить, что является проблемой - долгое выполнение запроса или большой массив данных в результате.

Для локализации проблемного запроса жожно воспользоваться профилеровщиком:

 - Активировать его командой `SET profiling = 1;`

 - Дождаться воспроизведения искомой ошибки

 - Выполнив команду `SHOW PROFILES;` определить долгий запрос по времени выполнения - колонка `Duration`

Также можно активировать автоматический сбор медленных запросов на уровне СУБД (не рекомендуется делать в production), для чего нужно внести в конфигурационный файл следующие строки:

  - `slow_query_log = 1` - Включение механизма логирования медленных запросов

  - `slow_query_log_file = /vr/log/mysql-slow.log` - Имя лог файла, куда будет сохраняться информация о медленных запросах

  - `long_query_time = 2` - Время в секундах, для классификации запросов как медленных

  - `log_queries_not_using_indexes` - Флаг, позволяющий добавлять в **slow_log** запросы, где не используются индексы

  - После внесения изменений перезапустить MySQL

Далее когда медленные запросы определены нужно воспользоваться командой `EXPLAIN` для поиска в них узкого места (при использовании профилеровщика текст запроса отображается в графе `Query`).

Если исследование проблемного запроса покажет, что запрос долго обрабатывается из-за своей сложности, то нужно произвести его оптимизацию, например:

- Добавить/Изменить индексы

- Если возможно, разбить один сложный запрос на несколько простых, забрав часть функций СУБД на клиентские части

- Разделить/Объединить/Переделать таблицы чтобы упростить запрос

- Нарастить аппаратные ресурсы

Если же запрос возвращает большоё объём данных и следовательно не хватает времени на их передачу, то можно:

- На стороне SQL сервера увеличить таймаут передачи данных - скорректировать значение `net_read_timeout` в конфигурационном файле MySQL

- Разделить один большой запрос на несколько частей ограничив вывод директивами `LIMIT` и `OFFSET`, например: `SELECT * FROM data LIMIT 1000 OFFSET 2000;` - ограничить вывод 1000 записями, причём начать вывод с 2000 (получить результаты с 2000 до 3000 строки)

- Ускорить/Улучшить сетевое соединение между клиентами и сервером

---

## Обязательная задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

### **Решение:**

Сообщение `postmaster invoked oom-killer` говорит о том, что операционная система принудительно убивает процесс, потребляющий чрезмерный объём памяти (происходит когда заканчивается ОЗУ. `oom = OutOfMemory`)

При принудительном закрытии процесса, обрабатывающего SQL запрос клиент продолжает ожидать ответ, что в итоге приводит к разрыву соединения и временной недоступности базы на стороне клиента до момента переподключения.

Для решения задачи можно:

- Изучить вывод **EXPLAIN** для проблемных запросов и попробовать оптимизировать таблицу, либо запрос (например, уменьшить объём коммитов или разделить запросы на несколько более мелких)

- Проверить конфигурацию PostgreSQL - возможно для СУБД установлено слишком высокое пределы буферов, например `shared_buffer` которые превышают имеющуюся ОЗУ

- Если данные получаются из одной большой таблицы, то можно применить **программный mapReduce** - разделить таблицу на части по определённому условию: диапазону какого-нибудь идентификатора (например, **от 1 до 100** - таблица `data_1`, **от 101 до 200** - таблица `data_2` и т.д.), группировкой (например, для какого-нибудь столбца **= 1** - таблица `data_1`, для **= 2** - таблица `data_2`), либо группировкой по списку значений

- Увеличить объём ОЗУ сервера

- Если используется один сервер PostgreSQL, то можно применить **аппаратный mapReduce** преобразовав его в кластер и разделив таблицу на части, разнесённые по разным серверам

### *Дополнние от преподавателя (**Олег Букатчук**):*

*Можно поиграть с параметрами, которые регулируют память в Postgres из основных это: [max_connections](https://www.postgresql.org/docs/current/runtime-config-connection.html), [shared_buffer, work_mem, maintenance_work_mem](https://www.postgresql.org/docs/14/runtime-config-resource.html), [effective_cache_size](https://www.postgresql.org/docs/14/runtime-config-query.html).*

*`shared_buffer` - этот параметр устанавливает, сколько выделенной памяти будет использоваться PostgreSQL для кеширования.*

*`wal_buffers` - PostgreSQL сначала записывает записи в WAL (журнал пред записи) в буферы, а затем эти буферы сбрасываются на диск. Размер буфера по умолчанию, определенный wal_buffers, составляет 16 МБ. Но если у нас много одновременных подключений, то более высокое значение может повысить производительность.*

*`effective_cache_size` - предоставляет оценку памяти, доступной для кэширования диска. Это всего лишь ориентир, а не точный объем выделенной памяти или кеша. Он не выделяет фактическую память, но сообщает оптимизатору объем кеша, доступный в ядре. Если значение этого параметра установлено слишком низким, планировщик запросов может принять решение не использовать некоторые индексы, даже если они будут полезны. Поэтому установка большого значения всегда имеет смысл.*

*`work_mem` - если нам нужно выполнить сложную сортировку, увеличьте значение work_mem для получения хороших результатов. Сортировка в памяти происходит намного быстрее, чем сортировка данных на диске. Установка очень высокого значения может стать причиной узкого места в памяти для нашей среды, поскольку этот параметр относится к операции сортировки пользователя.*

*`maintenance_work_mem` - это параметр памяти, используемый для задач обслуживания.*

---

## Дополнительные материалы по **Redis**

Проверка задержки ответа сервера **Redis**: `redis-cli --latency -h <host> -p <port>`, где `<host>` - хост и `<port>` - порт сервера откуда мы запрашиваем данные

Проверка **Redis** на наличие блокирующих slow команд: `redis-cli SLOWLOG GET N`

Отключения **huge_page** на уровне ядра: `echo never > /sys/kernel/mm/transparent_hugepage/enabled && systemctl restart redis`

Проверка задержек на уровне VM: `redis-cli --intrinsic-latency 100`
