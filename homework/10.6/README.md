# Домашнее задание по лекции "10.6. Инцидент-менеджмент"

## Постановка задачи

> Составьте постмотрем, на основе реального сбоя системы Github в 2018 году.
> 
> Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/), а
> также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

Краткое описание разделов (из презентации):
  - Краткое описание инцидента - краткая выжимка о инциденте
  - Предшествующие события - что произошло перед инцидентом
  - Причина инцидента - из-за чего возник инцидент
  - Воздействие - на что повлиял инцидент
  - Обнаружение - когда и как инцидент был обнаружен
  - Реакция - кто ответил на инцидент, кто был привлечен, какие каналы коммуникации были задействованы
  - Восстановление - описание действий по устранению инцидента и поведение системы
  - Таймлайн - последовательное описание ключевых событий инцидента с указанием времени
  - Последующие действия - что нужно предпринять, чтобы инцидент не повторялся

## Решение - Постмотрем

Раздел | Сбой системы GitHub 21 октября 2018
   --- | ---
Краткое описание инцидента | После непродолжительной потери связи между сетевым узлом и датацентром нарушилась топология кластеров Оркестратора, что привело к деградированию системы
Предшествующие события     | Плановые работы по замене вышедшего из строя 100G оптического оборудования в дата-центре на восточном побережье США
Причина инцидента          | В результате временной потери связи кластеры MySQL перешли в "неожиданное" для Оркестратора состояние (только западные). Нормальное состояние: ![normal](https://github.blog/wp-content/uploads/2018/10/normal-topology.png) Состояние после сбоя: ![bad](https://github.blog/wp-content/uploads/2018/10/invalid-topology.png)
Воздействие                | Отображение устаревшей и непоследовательной информации. Также в большинстве случаев не функционировали **WebHook** и сборка и публикация **GitHub Pages**
Обнаружение                | Инцидент был замечен дежурными инженерами через оповещения системы мониторинга
Реакция                    | Группа реагирования провела минимизацию накопления сложности инцидента (отключила часть сервисов для минимизации изменений БД), после чего подключились к работе координатор и дополнительные разработчики из инженерной группы БД. Из-за приоритета целостности данных общее время восстановления составило 24 часа 11 минут
Восстановление             | Для исключения потери данных временно отключили часть сервисов для мининизации накопления изменений, после чего восстановили данные из резервных копий, а на них реплицировали накопленные. Далее вручную переконфигурировали топологию кластеров БД и включили деактивированный функционал. Завершающим этапом дождались отработки накопленных задач для чего даже потребовалось временно развернуть дополнительные реплики на чтение. ![recovery](https://github.blog/wp-content/uploads/2018/10/recovery-flow.png)
Таймлайн                   | **21 октября 2018, 22:52 UTC** - Нарушилась связь между сетевым узлом и основным дата-центром на восточном побережье США<br> **21 октября 2018, 22:52 UTC** - Оркестратор в основном дата-центре запустил процесс выбора нового лидера, в результате чего начал создавать топологию кластера БД на западе. После восстановления подключения приложения направили трафик по записи на новые основные сервера на западе. Таким образом на обоих серверах образовались данные, отсутствующие у другого и не получилось вернуть первичный сервер не восток<br> **21 октября 2018, 22:54 UTC** - Внутренние системы мониторинга начали генерировать оповещения о многочисленных сбоях в работе систем<br> **21 октября 2018, 23:02 UTC** - Инженеры первой группы реагирования определили, что топологии для многочисленных кластеров БД находятся в неожиданном состоянии - при запросе API Оркестратора отображалась топология репликации БД, содержащая только серверы из западного ЦОД.<br> **21 октября 2018, 23:07 UTC** - Группа реагирования вручную заблокировала внутренние средства развёртывания, чтобы предотвратить внесение дополнительных изменений в БД<br> **21 октября 2018, 23:09 UTC** - Группа реагирования установила жёлтый статус работоспособности сайта (статус активного инцидента)<br> **21 октября 2018, 23:11 UTC** - Координатор присоединился к работе и через две минуты принял решение изменить статус сайта на красный.<Br> **21 октября 2018, 23:13 UTC** - К работе привлекли дополнительных разработчиков из инженерной группы БД, которые начали исследовать текущее состояние для определения необходимых действий для ручной перенастроийки БД<br> **21 октября 2018, 23:19 UTC** - В целях сохранности данных принято решение об остановке выполнения заданий, которые пишут метаданные типа пуш-запросов<br> **22 октября 2018, 00:05 UTC** - Инженеры из группы реагирования начали разрабатывать план устранения несогласованности данных и запустили процедуры отработки отказа для MySQL<br> **22 октября 2018, 00:41 UTC** - Инициирован процесс резервного копирования для всех затронутых кластеров MySQL. Одновременно нескольок групп инженеров изучали способы ускорения передачи и восстановления без дальнейшей деградации сайта или риска повреждения данных<br> **22 октября 2018, 06:51 UTC** - Несколько кластеров на востоке завершили восстановление из резервных копий и начали реплицировать новые данные с Западным побережьем<br> **22 октября 2018, 07:46 UTC** - Публикация информационного сообщение об инциденте<br> **22 октября 2018, 11:12 UTC** - Все первичные БД вновь переведены на Восток, но не смотря на возросшую производительность сайта некоторые данные всё ещё отставали на несколько часов из-за отложенных реплик<br> **22 октября 2018, 13:15 UTC** - Зафиксировано возрастание отставания репликации до согласованного состояния (время увеличивалось, а не уменьшалось). Начали подготовку дополнительных реплик чтения MySQL в общедоступном облаке Восточного побережья<br> **22 октября 2018, 16:24 UTC** - Завершена синхронизация реплик - возврат к исходной топологии. Устранинены проблемы задержки и доступности. Однако, красный статус сохранён, так как нужно ещё обработать накопленные данные.<br> **22 октяюря 2018, 16:45 UTC** - Включение всех дэактивированных функций. Корректировка TTL более 200000 истекших за время восстановления задач из более 5 миллионов.<br> **22 октября 2018, 23:03 UTC** - Все незавершённые события **webhook** и сборки **Pages** обработаны, а целостность и правильная работа всех систем подтверждена. Статус сайта изменён на зелёный
Последующие действия       | Введена системная практика проверки сценариев сбоев, предже чем они возникнут в реальности (**Chaos Engineering**)

---

> Пример из презентации
> 
> Раздел | Описание
> --- | ---
> Краткое описание инцидента | Около 2х часов ночи увеличилась утилизация ЦПУ на сервере. Вследствие этого часть сервисов стала недоступна.
> Предшествующие события     | Была установка патча 1.1 на сервис pretty
> Причина инцидента          | В патче 1.1 был допущен баг, в котором происходила многократная повторяющаяся запись на диск файлов.
> Воздействие                | Также на сервере с сервисом pretty был сервис корзины интернет магазина. Заказ товаров был недоступен для 100% пользователей в течении 15 минут.
> Обнаружение                | Инцидент был замечен дежурным инженером. Затем были привлечены ответственные разработчики.
> Реакция                    | Ответственные разработчики устранили инцидент за 15 минут.
> Восстановление             | Был установлен минорный патч 1.1.1, устраняющий данную проблему и система перешла к штатной работе. Нагрузка сервера упала сразу после установки патча, корзина стала доступна для заказов
> Таймлайн                   | 01:55 прилетел алёрт о утилизации ЦПУ <br> 01:57 дежурный инженер проинформировал о сбое ответственные лица <br> 02:00 была проведена инспекция кода последнего патча и найдена проблема <br> 02:05 был сделан коммит, устраняющий проблему <br> 02:09 прошла автоматическая сборка и выкатка сервиса pretty <br> 02:10 система заработала в штатном режиме
> Последующие действия       | Была заведена задача в issue tracker (ZADCH-123) по добавлению дополнительных модульных тестов на узкое место кода.

Перевод оригинальной статьи [October 21 post-incident analysis](https://habr.com/ru/post/428409/) за авторством **Jason Warner** от **Анатолия Ализара** [@m1rko](https://habr.com/ru/users/m1rko/)
